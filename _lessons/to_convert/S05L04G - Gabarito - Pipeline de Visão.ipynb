{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista Teórica 04 - Pipeline de Visão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Por que é importante identificar e tratar outliers antes de treinar um modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers podem influenciar negativamente o treinamento, levando o\n",
    "modelo a aprender padrões irrelevantes. Técnicas como remoção, imputação\n",
    "ou transformação podem ser usadas para lidar com eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Em que situações faz sentido converter imagens coloridas para escala de cinza?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a informação de cor não é relevante para a tarefa, como na\n",
    "análise de imagens médicas, a conversão para escala de cinza pode reduzir a\n",
    "dimensionalidade sem perda significativa de informação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Quais técnicas podem ser utilizadas para remover ruídos de imagens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtros como média, mediana e Gaussian Blur são amplamente usados para suavizar ruídos, enquanto preservam bordas importantes na imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Quando a remoção de fundo de uma imagem é necessária? Como ela pode ser feita?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É útil em tarefas onde o objeto de interesse precisa ser isolado, como em detecção de objetos. Técnicas incluem segmentação automática, máscaras manuais ou modelos baseados em aprendizado profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Qual o propósito e benefícios de realizar aumento de dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aumento de dados é uma técnica usada para aumentar artificialmente o tamanho de um conjunto de dados, criando versões modificadas dos dados existentes. Pode melhorar o desempenho dos modelos de aprendizado de máquina, fornecendo exemplos de treinamento adicionais e reduzindo o overfitting. Também pode tornar o modelo mais robusto a mudanças na distribuição dos dados e melhorar sua capacidade de generalização. O aumento de dados também pode ajudar a mitigar os efeitos da disponibilidade limitada de dados e permitir o uso de modelos maiores e mais complexos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)**  Liste e explique pelo menos três técnicas de data augmentation para imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotação: altera a orientação da imagem, ajudando a generalizar o modelo.\n",
    "- Flip horizontal/vertical: aumenta a diversidade sem alterar a essência visual.\n",
    "- Alteração de brilho/contraste: simula condições de iluminação variadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** Como identificar e corrigir problemas de classes desbalanceadas em um dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise da distribuição de classes pode ser feita através de histogramas. Correções incluem oversampling de classes minoritárias, undersampling de classes majoritárias ou atribuição de pesos durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Explique as diferenças entre os conjuntos de treino, validação e teste. Qual a proporção ideal para esses conjuntos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de treino é usado para ajustar os pesos do modelo, o de validação para ajustar hiperparâmetros, e o de teste para avaliar a generalização. Proporções comuns são 70%-80% treino, 10%-15% validação e 10%-15% teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelagem e Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)** Qual a vantagem das CNNs em comparação com técnicas tradicionais de extração de features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As CNNs aprendem automaticamente features relevantes diretamente dos dados, reduzindo a necessidade de engenharia manual e sendo mais adaptáveis a diferentes tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** Explique a importância de escolher a learning rate corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma learning rate muito alta pode impedir a convergência, enquanto uma muito baixa torna o treinamento lento. Testes com valores escalonados ajudam a encontrar o valor ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11)** Considere o seguinte cenário: Você treinou um  modelo para classificar três tipos de rochas (arenito, calcário, e shale). Os resultados para um conjunto de teste são os seguintes:\n",
    "\n",
    "- Arenito: 80 amostras corretas, 10 incorretas.\n",
    "- Calcário: 70 amostras corretas, 20 incorretas.\n",
    "- Shale: 60 amostras corretas, 30 incorretas.\n",
    "\n",
    "Amostras incorretas são atribuídas igualmente às outras classes.\n",
    "\n",
    "Calcule a acurácia do modelo, e precisão, recall e F1-score para cada classe.\n",
    "\n",
    "<details>\n",
    "<summary>Dica:</summary>\n",
    "\n",
    "- **Acurácia**: $ \\dfrac{Acertos}{Total} $\n",
    "- **Precisão**: $ \\dfrac{TP}{TP+FP} $\n",
    "- **Recall**: $ \\dfrac{TP}{TP+FN} $\n",
    "- **F1-score**: $ 2\\times\\dfrac{Precisão \\times Recall}{Precisão + Recall} $\n",
    "\n",
    "<details>\n",
    "<summary>Onde para cada classe:</summary>\n",
    "\n",
    "- **TP**: Acertos da classe.\n",
    "- **FP**: Erros atribuídos à classe.\n",
    "- **FN**: Erros de outras classes que deveriam ser atribuídos à classe.\n",
    "\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acurácia**: \n",
    "- 270 Amostras no total\n",
    "- 210 Amostras corretas\n",
    "- 210/270 = 77% de acurácia\n",
    "\n",
    "**Classes**:\n",
    "- Arenito: TP = 80, FP = 25, FN = 10.\n",
    "- Calcário: TP = 70, FP = 20, FN = 20.\n",
    "- Shale: TP = 60, FP = 15, FN = 30.\n",
    "\n",
    "**Arenito**:\n",
    "- Precisão: 80/(80+25) = 0.7619\n",
    "- Recall: 80/(80+10) = 0.8980\n",
    "- F1-score: 2×0.76x0.89/(0.76+0.89) = 0.82\n",
    "\n",
    "**Calcário**:\n",
    "- Precisão: 70/(70+20) = 0.7778\n",
    "- Recall: 70/(70+20) = 0.7778\n",
    "- F1-score: 2×0.77x0.77/(0.77+0.77) = 0.77\n",
    "\n",
    "**Shale**:\n",
    "- Precisão: 60/(60+15) = 0.8\n",
    "- Recall: 60/(60+30) = 0.6667\n",
    "- F1-score: 2×0.8x0.66/(0.8+0.66) = 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12)** Explique por que o F1-score é uma métrica mais informativa do que a acurácia em cenários onde há desbalanceamento de classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O F1-score combina precisão e recall, sendo ideal em casos com desbalanceamento de classes. Por exemplo, em geociências, se classes como \"falha geológica\" são raras, a acurácia pode ser enganosa, enquanto o F1-score capta o desempenho equilibrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13)** Dado o seguinte conjunto de predições e rótulos reais para três classes (Arenito, Calcário, Shale):\n",
    "\n",
    "- Predições: [Arenito, Arenito, Calcário, Shale, Calcário, Shale, Shale, Arenito]\n",
    "- Rótulos reais: [Arenito, Calcário, Calcário, Shale, Arenito, Shale, Calcário, Arenito]\n",
    "\n",
    "Construa a matriz de confusão e identifique os padrões de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Real \\ Pred  | Arenito | Calcário | Shale |\n",
    "|---           |---      |---       |---    |\n",
    "| **Arenito**  | 2       | 1        | 0     |\n",
    "| **Calcário** | 1       | 1        | 1     |\n",
    "| **Shale**    | 0       | 1        | 2     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14)** A partir da matriz de confusão construída no exercício anterior:\n",
    "\n",
    "- Qual classe é mais confundida?\n",
    "- O que isso pode indicar sobre o modelo ou os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe \"Calcário\" é mais confundida, indicando que o modelo tem dificuldade em distinguir essa classe. Isso pode indicar falta de representatividade no dataset ou padrões similares entre \"Calcário\" e outras classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15)** Explique o conceito de validação cruzada k-fold e como ela ajuda a avaliar a robustez do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validação cruzada divide os dados em k subsets. Cada subset é usado como conjunto de teste uma vez, e os outros k−1 subsets são usados como treinamento. Isso reduz o overfitting e avalia a robustez do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa: Classificação de Minerais em Imagens Geológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você recebeu um conjunto de dados geológicos contendo imagens de amostras de rochas. Sua tarefa é propor um pipeline completo de solução para classificar minerais específicos presentes nas amostras, ou seja, atribuir um único rótulo a cada imagem. O pipeline deve considerar **pré-processamento**, **preparação do dataset**, **treinamento de um modelo**, e **avaliação**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline de Solução Detalhado**\n",
    "\n",
    "1. **Pré-processamento**\n",
    "    1. *Entendimento e Preparação Inicial*\n",
    "        1. *Análise do Dataset*:\n",
    "            - Verifique o tamanho do dataset e a resolução das imagens.\n",
    "            - Analise as classes (tipos de minerais) e a quantidade de amostras por classe.\n",
    "        2. *Formato e Anotações*:\n",
    "            - Certifique-se de que as imagens estão em formatos suportados (`.png` ou `.jpg`).\n",
    "            - Verifique se as anotações (rótulos) estão disponíveis em um formato estruturado (como CSV ou JSON).\n",
    "    2. *Normalização das Imagens*:\n",
    "        - Redimensione as imagens para, por exemplo, $ 224 \\times 224 $ pixels (compatível com CNNs pré-treinadas).\n",
    "        - Normalize os valores de pixel para a faixa $ [0, 1] $, reduzindo as chances de vanishing/exploding gradiente, e ajudando na convergência.\n",
    "    3. *Remoção de Ruído*:\n",
    "        - Use filtros Gaussian Blur ou mediana para remover ruídos de fundo sem comprometer as bordas importantes.\n",
    "    4. *Equalização de Histograma*:\n",
    "        - Aplique equalização para melhorar o contraste das imagens, caso haja variação significativa na iluminação.\n",
    "    5. *Rotulagem Consistente*:\n",
    "        - Padronize os rótulos para evitar inconsistências (e.g., \"Quartz\" vs. \"quartz\").\n",
    "2. **Preparação do Dataset**\n",
    "    1. *Divisão do Dataset*:\n",
    "        - Separe o dataset em 70% para treino, 15% para validação e 15% para teste.\n",
    "        - Certifique-se de que a divisão seja estratificada, preservando a proporção das classes em cada conjunto.\n",
    "    2. *Análise de Balanceamento*:\n",
    "        - Verifique a distribuição de imagens por classe.\n",
    "    3. *Correção de Desequilíbrio*:\n",
    "        - Use oversampling nas classes minoritárias com técnicas de data augmentation (explicadas abaixo).\n",
    "    4. *Data Augmentation*\n",
    "        1. *Aumentar a Diversidade dos Dados*:\n",
    "            - Rotação aleatória (até 30°).\n",
    "            - Flips horizontais e verticais.\n",
    "            - Alteração de brilho (±20%).\n",
    "            - Crop aleatório para simular diferentes ângulos de visão.\n",
    "            - Adição de ruído simulado para testar robustez.\n",
    "        2. *Validação das Transformações*:\n",
    "            - Visualize as imagens geradas para garantir que as transformações são realistas.\n",
    "3. **Treinamento do Modelo**\n",
    "    1. *Escolha da Arquitetura*:\n",
    "        - Use uma arquitetura pré-treinada, como ResNet50, para transfer learning.\n",
    "        - Congele as primeiras camadas e ajuste as camadas finais para a quantidade de classes.\n",
    "    2. *Função de Perda* e Otimização:\n",
    "        - Escolha cross-entropy como função de perda.\n",
    "        - Use Adam ou SGD com uma learning rate inicial de 0.001.\n",
    "    2. *Configuração do Treinamento*:\n",
    "        - Configure o treinamento para 50 épocas com early stopping baseado na métrica de validação.\n",
    "        - Use batches de tamanho 32.\n",
    "4. **Avaliação**\n",
    "    1. *Métricas Primárias*:\n",
    "        - Acurácia, precisão, recall e F1-score por classe.\n",
    "    2. *Métricas Secundárias*:\n",
    "        - Matriz de confusão para identificar padrões de erro.\n",
    "        - Análise de curvas ROC por classe (se houver muitas classes, escolha as mais relevantes).\n",
    "    3. *Validação Cruzada*:\n",
    "        - Realize validação cruzada k-fold para avaliar a robustez do modelo.\n",
    "    4. *Interpretação e Melhorias*\n",
    "        1. *Análise de Erros*:\n",
    "            - Inspecione exemplos mal classificados para entender possíveis falhas.\n",
    "        2. *Explicabilidade do Modelo*:\n",
    "            - Use técnicas como [Grad-CAM](https://arxiv.org/abs/1610.02391) para visualizar as regiões de interesse do modelo em cada imagem.\n",
    "        3. *Iteração*:\n",
    "            - Ajuste hiperparâmetros ou refine o dataset com base na análise de erros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
